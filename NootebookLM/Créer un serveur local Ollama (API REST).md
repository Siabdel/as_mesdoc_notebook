



# CrÃ©er un serveur local Ollama (API REST)

> Created le 8 Janvier 2026
>
> Author : SA





* crÃ©er un **serveur local Ollama (API REST)**
* choisir **les meilleures quantizations pour RTX 3060**
* crÃ©er un **serveur local Ollama (API REST)**
* comparer **mistral vs deepseek vs qwen** pour usage **strictement mÃ©tier**
* brancher Ollama sur **PDF (factures, budgets) avec RAG**
*  **Analyser des PDF (factures/budgets) avec Ollama**
* ğŸ§  **RAG local (FAISS / Chroma)**
* âš™ï¸ **Prompt mÃ©tier ultra-strict (rÃ¨gles business)**
* ğŸš€ **Benchmark RTX 3060 (VRAM / perf)**
*  **Docker-compose complet** (Django + Postgres + Redis + Qdrant + MinIO + n8n + LLM + Embeddings + OCR)
* ğŸ”¹ **Un frontend Vue.js chat RAG** fonctionnel
*  ğŸ”¹ **Le script Python `save_to_minio()`**
*  ğŸ”¹ **Le service embeddings complet (FastAPI)**
*  ğŸ”¹ **Le service OCR PyMuPDF complet**
*  ğŸ”¹ **Le service Whisper complet (FastAPI)**



---

* **Docker-compose complet** (Django + Postgres + Redis + Qdrant + MinIO + n8n + LLM + Embeddings + OCR)
*  ğŸ”¹ **Un frontend Vue.js chat RAG** fonctionnel
*  ğŸ”¹ **Le script Python `save_to_minio()`**
*  ğŸ”¹ **Le service embeddings complet (FastAPI)**
*  ğŸ”¹ **Le service OCR PyMuPDF complet**
*  ğŸ”¹ **Le service Whisper complet (FastAPI)**